{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c8178ba-2ea0-4f4f-b9ca-c3435a83bd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my virtual environments are rarely properly connected to jupyter so this fixes that. \n",
    "# you prolly won't need this cell but running it won't hurt anything either\n",
    "import sys\n",
    "import os\n",
    "current_dir = os.getcwd()  # Get the current working directory\n",
    "venv_dir = os.path.join(current_dir, 'venv') \n",
    "python_version = str(sys.version_info.major) + '.' + str(sys.version_info.minor)\n",
    "site_packages_path = os.path.join(venv_dir, 'lib', 'python' + python_version, 'site-packages')\n",
    "sys.path.append(site_packages_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0918a651-5c6a-4a39-8b3e-a28259e4fd64",
   "metadata": {},
   "source": [
    "# Load a Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39c0ba50-83de-4ad7-b262-944e6d547ae9",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Model:\n\tMissing key(s) in state_dict: \"output.weight\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtemplateGPT_1m_5ft11_and_skinnyfat\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_model\n\u001b[0;32m---> 15\u001b[0m model, tokenizer, cfg \u001b[38;5;241m=\u001b[39m load_model(name)\n",
      "File \u001b[0;32m~/local-repos/micro-GPT-sandbox/models/templateGPT/tools.py:164\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(name, device)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;66;03m# Load the saved state dictionary\u001b[39;00m\n\u001b[1;32m    163\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/model.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 164\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(path)) \n\u001b[1;32m    166\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msum\u001b[39m(p\u001b[38;5;241m.\u001b[39mnumel()\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mp\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters())\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m1e3\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mK parameters\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mcfg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model, tokenizer, cfg\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:2152\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2147\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2148\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2149\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2153\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Model:\n\tMissing key(s) in state_dict: \"output.weight\". "
     ]
    }
   ],
   "source": [
    "## pretrained model options:\n",
    "# a 1m parameter model trained for 2000 iters with many layers, thin MLP hidden dimensions & few attention heads: 'templateGPT_1m_tall_and_skinny'\n",
    "# a 1m parameter model trained for 2000 iters with layers, MLP hidden dimensions, & attention heads bw the other two: 'templateGPT_1m_5ft11_and_skinnyfat'\n",
    "# a 1m parameter model trained for 2000 iters with few layers, thick MLP hidden dimensions & many attention heads: 'templateGPT_1m_short_and_thicc'\n",
    "# a 2m parameter model trained for 4000 iters with CosineNorm: 'templateGPT_2m_CosineNorm'\n",
    "# a 2m parameter model trained for 4000 iters with LayerNorm: 'templateGPT_2m_LayerNorm'\n",
    "# a 2m parameter model trained for 4000 iters with RMSNorm: 'templateGPT_2m_RMSNorm'\n",
    "# a 3m parameter model trained for 5000 iters with a gated MLP: 'templateGPT_3m_GatedMLP'\n",
    "# a 3m parameter model trained for 5000 iters with an old-fashioned MLP: 'templateGPT_3m_GatedMLP'\n",
    "# a 4m parameter model trained for 6000 iters with GeGLU activation: 'templateGPT_4m_GeGLU'\n",
    "# a 4m parameter model trained for 6000 iters with SwiGLU activation: 'templateGPT_4m_SwiGLU'\n",
    "name = 'templateGPT_1m_5ft11_and_skinnyfat'\n",
    "\n",
    "from tools import load_model\n",
    "model, tokenizer, cfg = load_model(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c971fce-8b3e-4732-bd66-d5d2028025d6",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a366b1fc-b620-45a0-8b42-71bdca18906d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference import generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c202ea0-e64d-4367-a4a6-102756fe63b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once| |upon| |a| |ti|me|, |th|er|e| |was| |a| |boy| |na|me|d| |Tim|. \n"
     ]
    }
   ],
   "source": [
    "# take a look at the tokenizer\n",
    "prompt = \"Once upon a time, there was a boy named Tim. \"\n",
    "print(tokenizer.display(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5b13a76-50f8-48b6-b7cf-9097d307c6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, there was a boy named Tim. He had a long little with a fun day. He loved to play with his mom and dad. He had a small cat and did not want to play with the day.\n",
      "One day, Max saw a big dog named Max wanted to show the beach in the ball.\n",
      "Tim and his mom found a little bird to play in the park. The big dog was not happy. He had an idea. He thought the boat went for him. He knew the man was scared and saw the color he was so happy. He said, \"I want to play a clean to help him. The little boy was very happy and carefully played with the day and didn't know what he could not find him. He could not like a nice from the park and asked him. The dog was sad and tried to take it away with his new toy car. They did not dry for the fan together. They played together and had fun happily. The other is happy and thanked the rock to be good.\n"
     ]
    }
   ],
   "source": [
    "output = generate(\n",
    "    prompt, \n",
    "    model, \n",
    "    tokenizer,\n",
    "    #temperature = 0.5, # default value is 0.7\n",
    "    #top_k = 32, # default value is 50\n",
    "    #top_p = 0.8, # default value is 0.9\n",
    "    #max_gen_len = 420, # default value is None\n",
    "    #memory_saver_div = 2, # default value is 1, AKA no memory saving\n",
    ")\n",
    "print(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "114de8bf-ab76-460d-8c37-ebe368b47e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, there was a boy named Tim. Tim had a very sparky with his friends. One day, they saw a big tree in the sky. The cat was very sad. Tim wanted to see the bunny and said, \"That is a big, red ball and a green broken the man. It was a big dog, and he would play with his mom and said, \"I can't know what you see my kind again!\" said the ball with a lot of fun together. They were not happy to see the car to make a big fish. Tim was happy and said, \"What are you glad this need to catch it and saw the car. The bird was happy and learn and said, \"Yes, I want to climb the hat to help her coming playing with the story is can and playing together in the trees and could get it.\n",
      "After they had a dress in the park and played together every day. \n",
      "\n",
      "Once upon a time, there was a girl named Lucy. She had a momess named Lily. It was a big, but threw to play with her mom. She had a big book and found a pictures on the park.\n",
      "One day, the perfect garden was so pretty flying on the family. She was very happy and said, \"I'm sorry, please?\" Lily said, \"I am a small kind called to help her not to play. Her mom said that her ball and started to play with her mom. She had an idea. He told them a ball to have them and dance to the minum. Tom was so happy to be scared. She was so happy and for a friend dog who was happy and put it in the park with her new doll. Sue was happy and happy and went to her friends when it was safe and the bug and helped the creat and he had an idea. Sue was happy to help him and said, \"Thank you, Lily. I can we play with me?\"\n",
      "Lily said, \"Yes, you help you can be so happy to see the little girls. They went back to the pa \n",
      "\n",
      "Once upon a time, there was a little boy named Tim. Tim had a sunny rock. He liked to play outside. One day, Tim saw a big pink in the sky. He wanted to play with his toy with his mom. The bird was so happy that the big flowers. They had a big toy fish. The dog was very happy. He thought it was a big bear came. He was very excited and said, \"I want to play with you all day!\" Lily smiled and said, \"Yes, you like to reach the ground together!\" They went to the tree and they were sad and the boy. They played together together and had lots of fun. They had a big cat with the cat and played together every day. They had a lot of fun and playing with their favorite friends. \n",
      "\n",
      "There once was a big sky named Tom. Tom was a big ball with a big girl named Lily. She had a very nice to play with her mom. He had a big tree and went to make a long house. She had a toy noise to show it. It was a nice toy picture and under a bite. The cat was a long time to play. He wanted to take him and day everyone. She looked around and helping her friends and worked to play. The bird said, \"It's a magic for you!\" The cat wanted to help the cat. She shouted back to the box. She put the special fish and make a broke. The bird was happy and said, \"We don't have a big tree! I was a big, but hugged it was playing and didn't know what to keep the old. The apple felt better and the end of the ground. The cat said, \"I can help you need to be kind and the room with the other for the bunny fish. He wanted to help the cat  \n",
      "\n",
      "There once was a boy named Tim. Tim loved to play with his toys in the water. Tim was very excited and saw a big tree. Tim liked to play with his toys. Tim was very happy. He wanted to help the blocks and said, \"I am my toy car. I am a big park and wanted to play with it.\"\n",
      "Tim and his mom learned that it in the park. Tim was happy and had a fun day and a dream with the toy car. They played together in the park and played together every day. They were so happy to stay with their friends. They all became good at the tree with the box. They had a great day on the house. They were happy to learn and said, \"I can you have to help the bed will long and had lots of fun again. \n",
      "\n",
      "There once was a girl named Lily. She had a confun to play with her friends. They were very happy. They had a big box. They went to the park with the little girl. She said, \"I want to fly here!\" Lily and Sue came out that she put it on it. They played and running outside.\n",
      "One day, a little girl named Sue. She went to the park and the farm had so much. The block and the store is many fun and the lion. The cat was sad and hugged the family. The ball was a long time and made the cat and the mouse is not friends. They played together and had a big ball with the ball. They played with the pond and put the piece on the tall and you can talk. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"Once upon a time, there was a boy named Tim. \", \n",
    "    \"Once upon a time, there was a girl named Lucy. \", \n",
    "    \"Once upon a time\", \n",
    "    \"There once was a\", \n",
    "    \"There once was a boy\", \n",
    "    \"There once was a girl\"\n",
    "]\n",
    "outputs = generate(\n",
    "    prompts, \n",
    "    model, \n",
    "    tokenizer,\n",
    "    #temperature = 0.6, # default value is 0.7\n",
    "    #top_k = 32, # default value is 50\n",
    "    #top_p = 0.85, # default value is 0.9\n",
    "    #max_gen_len = 420, # default value is None\n",
    "    #memory_saver_div = 2, # default value is 1, AKA no memory saving\n",
    ")\n",
    "for o in outputs:\n",
    "    print(o, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfe1aab-64b3-4cce-a53c-50ac62d44e88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
