{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c8178ba-2ea0-4f4f-b9ca-c3435a83bd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my virtual environments are rarely properly connected to jupyter so this fixes that. \n",
    "# you prolly won't need this cell but running it won't hurt anything either\n",
    "import sys\n",
    "import os\n",
    "current_dir = os.getcwd()  # Get the current working directory\n",
    "venv_dir = os.path.join(current_dir, 'venv') \n",
    "python_version = str(sys.version_info.major) + '.' + str(sys.version_info.minor)\n",
    "site_packages_path = os.path.join(venv_dir, 'lib', 'python' + python_version, 'site-packages')\n",
    "sys.path.append(site_packages_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0918a651-5c6a-4a39-8b3e-a28259e4fd64",
   "metadata": {},
   "source": [
    "# Load a Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39c0ba50-83de-4ad7-b262-944e6d547ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4011.456K parameters\n",
      "ModelConfig(dim=192, device='cpu', tokenizer='bpe_v1_tinyStories', vocab_len=8192, num_layers=6, second_resid_norm=False, mlp_hidden_mult=4, mlp_bias=False, mlp_nonlinearity='SiLU', mlp_gated=True, num_q_heads=2, num_kv_heads=1, head_dim=96, theta=10000, max_seq_len=512, scale_first_resid=True, norm_type='RMSNorm', norm_affine=True, norm_bias=True, eps=1e-06)\n",
      "Model(\n",
      "  (token_embedder): Embedding(8195, 192)\n",
      "  (layers): ModuleList(\n",
      "    (0-5): 6 x Layer(\n",
      "      (pre_attn_norm): Norm()\n",
      "      (attn): MQA(\n",
      "        (Wq): Linear(in_features=192, out_features=192, bias=False)\n",
      "        (Wk): Linear(in_features=192, out_features=96, bias=False)\n",
      "        (Wv): Linear(in_features=192, out_features=96, bias=False)\n",
      "        (Wo): Linear(in_features=192, out_features=192, bias=False)\n",
      "      )\n",
      "      (pre_mlp_norm): Norm()\n",
      "      (mlp): MLP(\n",
      "        (Wup): Linear(in_features=192, out_features=512, bias=False)\n",
      "        (Wgate): Linear(in_features=192, out_features=512, bias=False)\n",
      "        (Wdown): Linear(in_features=512, out_features=192, bias=False)\n",
      "        (nonlinearity): SiLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (final_norm): Norm()\n",
      "  (criterion): CrossEntropyLoss()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "## pretrained model options:\n",
    "# a 1m parameter model trained for 2000 iters with many layers, thin MLP hidden dimensions & few attention heads: 'templateGPT_1m_tall_and_skinny'\n",
    "# a 1m parameter model trained for 2000 iters with layers, MLP hidden dimensions, & attention heads bw the other two: 'templateGPT_1m_5ft11_and_skinnyfat'\n",
    "# a 1m parameter model trained for 2000 iters with few layers, thick MLP hidden dimensions & many attention heads: 'templateGPT_1m_short_and_thicc'\n",
    "# a 2m parameter model trained for 4000 iters with CosineNorm: 'templateGPT_2m_CosineNorm'\n",
    "# a 2m parameter model trained for 4000 iters with LayerNorm: 'templateGPT_2m_LayerNorm'\n",
    "# a 2m parameter model trained for 4000 iters with RMSNorm: 'templateGPT_2m_RMSNorm'\n",
    "# a 3m parameter model trained for 5000 iters with a gated MLP: 'templateGPT_3m_GatedMLP'\n",
    "# a 3m parameter model trained for 5000 iters with an old-fashioned MLP: 'templateGPT_3m_GatedMLP'\n",
    "# a 4m parameter model trained for 6000 iters with GeGLU activation: 'templateGPT_4m_GeGLU'\n",
    "# a 4m parameter model trained for 6000 iters with SwiGLU activation: 'templateGPT_4m_SwiGLU'\n",
    "name = 'templateGPT_4m_SwiGLU'\n",
    "\n",
    "from tools import load_model\n",
    "model, tokenizer, cfg = load_model(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c971fce-8b3e-4732-bd66-d5d2028025d6",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a366b1fc-b620-45a0-8b42-71bdca18906d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference import generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c202ea0-e64d-4367-a4a6-102756fe63b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once| |upon| |a| |ti|me|, |th|er|e| |was| |a| |boy| |na|me|d| |Tim|. \n"
     ]
    }
   ],
   "source": [
    "# take a look at the tokenizer\n",
    "prompt = \"Once upon a time, there was a boy named Tim. \"\n",
    "print(tokenizer.display(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5b13a76-50f8-48b6-b7cf-9097d307c6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max attention matrix size in RAM will be 64x512 rather than 512x512\n",
      "\n",
      "Once upon a time, there was a boy named Tim. Tim had a big bag with his mom. He loved to play with his balling\n"
     ]
    }
   ],
   "source": [
    "output = generate(\n",
    "    prompt, \n",
    "    model, \n",
    "    tokenizer,\n",
    "    #temperature = 0.5, # default value is 0.7\n",
    "    #top_k = 32, # default value is 50\n",
    "    #top_p = 0.8, # default value is 0.9\n",
    "    #max_gen_len = 420, # default value is None\n",
    "    memory_saver_div = 8, # default value is 1, AKA no memory saving\n",
    ")\n",
    "print(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "114de8bf-ab76-460d-8c37-ebe368b47e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max attention matrix size in RAM will be 256x512 rather than 512x512\n",
      "\n",
      "Once upon a time, there was a boy named Tim. Tim had a big box with a big box. He liked to watch the box with his mom. One day, Tim saw a big box in the box. He wanted to know what was inside. He asked his mom, \"Mom, can I see it?\" His mom said, \"No, Tim. That box is not for you.\"\n",
      "Tim thought for a moment and said, \"I want to show you the box to the box.\" The box opened its eyes and said, \"No, Tim. You can play with your toys. I want to play with the     \n",
      "\n",
      "Once upon a time, there was a girl named Lucy. She loved to play outside. One day, she found a big box of toys in the yard. It was a big, soft terrible cat. Lucy was very happy and wanted to play with the toys.\n",
      "Lucy tried to open the box, but she could not find it. She was sad. She looked for her toy cat, but she could not find it. She looked under her bed and behind the tree. She was sad.\n",
      "Then, she saw a big dog stuck in a tree. Th  \n",
      "\n",
      "Once upon a time, there was a little boy named Tim. Tim had a big bag of toys and loved to play with. One day, Tim found a big box of toys in his room. He wanted to play with it, but he did not know what it was.\n",
      "Tim went to his friend, Sue, and said, \"I will teach you a big red ball!\" Sue and Tim played with the ball all day. They had lots of fun together. They had a lot of fun. But then, they saw a big                      \n",
      "\n",
      "There once was a big red ball. It was very special and scary. The ball was very happy and proud. He could not go fast anymore. He felt sad and wanted to play with it.\n",
      "One day, the ball went for a walk in the woods. He saw a big tree with lots of leaves. The ball was very hot and strong. The ball was very strong and he was very happy.\n",
      "The ball was very good at hiding and the ball was not his leg. He was very happy to.                  ,\" \n",
      "\n",
      "There once was a boy who had a big box of cereal. He liked to play with his toys and make everyone happy. He had a big box with a big box of cereal in his room.\n",
      "One day, the box was very pretty and making a cake. He was very excited. He wanted to see what was inside the box. He put the box in the box and started to draw. He put the box in his room and made the box with the box.\n",
      "The box was a very magic box. He was very happy .                  \n",
      "\n",
      "There once was a girl named Lucy. She loved to play outside. One day, she saw a big tree with a long neck. It was a big tree with a big hat and a long tail.\n",
      "Lucy asked her mom, \"Can I play with you?\" Her mom said, \"Yes, let's play together!\" They played with the tree and had lots of fun. Lucy was happy to play with her friends in the tree.\n",
      "At the end of the day, Lucy and her mom went to the tree to play. They saw                 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"Once upon a time, there was a boy named Tim. \", \n",
    "    \"Once upon a time, there was a girl named Lucy. \", \n",
    "    \"Once upon a time\", \n",
    "    \"There once was a\", \n",
    "    \"There once was a boy\", \n",
    "    \"There once was a girl\"\n",
    "]\n",
    "outputs = generate(\n",
    "    prompts, \n",
    "    model, \n",
    "    tokenizer,\n",
    "    temperature = 0.6, # default value is 0.7\n",
    "    top_k = 32, # default value is 50\n",
    "    top_p = 0.85, # default value is 0.9\n",
    "    max_gen_len = 420, # default value is None\n",
    "    memory_saver_div = 2, # default value is 1, AKA no memory saving\n",
    ")\n",
    "for o in outputs:\n",
    "    print(o, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfe1aab-64b3-4cce-a53c-50ac62d44e88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
